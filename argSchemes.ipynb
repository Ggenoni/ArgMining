{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"validation.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Example',\n",
       " 'CauseToEffect',\n",
       " 'PracticalReasoning',\n",
       " 'Consequences',\n",
       " 'Example',\n",
       " 'Consequences']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"CLINTON_199_2\"][\"schemes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemes = []\n",
    "for key, value in data.items():\n",
    "    schemes.extend(value[\"schemes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemes = set(schemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(schemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ad hominem',\n",
       " 'Alternatives',\n",
       " 'Analogy',\n",
       " 'ArgumentFromAuthority',\n",
       " 'Bias',\n",
       " 'CauseToEffect',\n",
       " 'CircumstantialAdHominem',\n",
       " 'Consequences',\n",
       " 'DangerAppeal',\n",
       " 'DirectAdHominem',\n",
       " 'ERAdHominem',\n",
       " 'ERExample',\n",
       " 'ERExpertOpinion',\n",
       " 'ERPracticalReasoning',\n",
       " 'Example',\n",
       " 'ExpertOpinion',\n",
       " 'FearAppeal',\n",
       " 'GenericAdHominem',\n",
       " 'NegativeConsequences',\n",
       " 'PopularOpinion',\n",
       " 'PopularPractice',\n",
       " 'PositionToKnow',\n",
       " 'PositiveConsequences',\n",
       " 'PracticalReasoning',\n",
       " 'Sign',\n",
       " 'SignFromOtherEvents',\n",
       " 'Values',\n",
       " 'VerbalClassification'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to ChatGpt:\n",
    "\n",
    "These are common argumentative schemes used in argumentation theory, often linked to Walton's argumentation schemes and informal logic. Here's a brief explanation of each:  \n",
    "\n",
    "- Ad Hominem – Attacking the person instead of addressing their argument.  \n",
    "- Alternatives – Presenting different options and weighing them against each other.  \n",
    "- Analogy – Arguing that because two things are similar in some respects, they are likely similar in another respect.  \n",
    "- Argument From Authority – Claiming something is true because an expert or authority endorses it.  \n",
    "- Bias – Accusing a source of partiality to undermine their argument.  \n",
    "- Cause to Effect – Asserting that one event leads to another.  \n",
    "- Circumstantial Ad Hominem – Suggesting that someone's circumstances or interests bias their argument.  \n",
    "- Consequences – Arguing for or against a claim based on its potential results.  \n",
    "- Danger Appeal (Fear Appeal) – Persuading by invoking fear of negative outcomes.  \n",
    "- Direct Ad Hominem – A more explicit and direct attack on a person rather than their argument.  \n",
    "- ER Ad Hominem – Likely an \"Explanation and Refutation\" variation of ad hominem.  \n",
    "- ER Example – Using an example as part of an explanation and refutation process.  \n",
    "- ER Expert Opinion – Using expert opinion within an explanation and refutation framework.  \n",
    "- ER Practical Reasoning – Using practical reasoning (cost-benefit analysis) to explain and refute a claim.  \n",
    "- Example – Using specific instances to support a general claim.  \n",
    "- Expert Opinion – Using an expert's judgment to support an argument.  \n",
    "- Fear Appeal – Same as \"Danger Appeal,\" invoking fear to persuade.  \n",
    "- Generic Ad Hominem – A broad category of ad hominem attacks.  \n",
    "- Negative Consequences – Arguing against a position by pointing out its harmful effects.  \n",
    "- Popular Opinion – Claiming something is true because many people believe it.  \n",
    "- Popular Practice – Justifying something based on its widespread acceptance.  \n",
    "- Position to Know – Arguing that someone is credible because they are in a position to have knowledge on the topic.  \n",
    "- Positive Consequences – Supporting a position by highlighting its beneficial effects.  \n",
    "- Practical Reasoning – Evaluating options based on practical consequences.  \n",
    "- Sign – Inferring a conclusion from observable signs or indicators.  \n",
    "- Sign From Other Events – A variation of the \"Sign\" scheme, using other occurrences as indirect evidence.  \n",
    "- Values – Arguing based on ethical, moral, or cultural values.  \n",
    "- Verbal Classification – Placing something into a category to support a claim.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'US2016', 'moral_maze_schemes', 'rrd', 'us2016reddit'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = []\n",
    "\n",
    "for _, value in data.items():\n",
    "    datasets.append(value[\"dataset\"])\n",
    "\n",
    "datasets = set(datasets)\n",
    "\n",
    "print(len(datasets))\n",
    "\n",
    "datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
